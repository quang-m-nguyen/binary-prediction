{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Initial timestamps\n",
    "from_timestamp = 1730526460\n",
    "to_timestamp = 1736526460\n",
    "\n",
    "# Headers from your curl command\n",
    "headers = {\n",
    "    'accept': '*/*',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "    'cookie': 'splash=1; .ASPXANONYMOUS=JQBcO1QOT1rbvq_3-d8KJhH3tQqA9SOmqRrarUIooewzrectqjk9KNwOSrtIeso5VOaUFUIAgbbn9d3OonhDPdNSKsdSpHZmShwkPkX_8wf4y8NstB_J82_Pk2jWYq_OMMKRvicGNzMGrgKhLX3YSg2; FrnHOST=state%3D%7B%22logged%22%3A%220%22%2C%22roles%22%3A%22%5B%5C%22Guest%5C%22%5D%22%7D; __RequestVerificationToken=lyQb38XIBx0zn41oFbCWZFWqKhhwEmadXq_ZQz0HgpGXKTUktG2VOjTRebBU8k57Gf7sKtGmtOg2EVJgPii6O8NLir6CkF3jLMDfstCeQCM1; g_state={\"i_p\":1730550930561,\"i_l\":1}',\n",
    "    'dnt': '1',\n",
    "    'priority': 'u=1, i',\n",
    "    'referer': 'https://www.cashbackforex.com/chart?s=BTC.USD-1m',\n",
    "    'sec-ch-ua': '\"Not?A_Brand\";v=\"99\", \"Chromium\";v=\"130\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"macOS\"',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "\n",
    "for _ in range(30):\n",
    "    # Construct URL with current timestamps\n",
    "    url = f'https://www.cashbackforex.com/api/live-chart/datafeed/bars?symbol=IC%20Markets:BTCUSD&resolution=1&from={from_timestamp}&to={to_timestamp}&countback=100000'\n",
    "    \n",
    "    # Make the request\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = response.json()\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Save to CSV\n",
    "    filename = f'{from_timestamp}_{to_timestamp}.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "    # Update timestamps for next iteration (moving backward in time)\n",
    "    to_timestamp = from_timestamp\n",
    "    from_timestamp -= 6000000\n",
    "    \n",
    "    # Add a small delay to be nice to the server\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If milliseconds: 2019-04-01 11:27:00\n",
      "If seconds: 2019-04-01 11:27:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# For milliseconds timestamp (13 digits)\n",
    "timestamp_ms = 1554092820000\n",
    "datetime_ms = datetime.fromtimestamp(timestamp_ms/1000)\n",
    "print(f\"If milliseconds: {datetime_ms}\")\n",
    "\n",
    "# For seconds timestamp (10 digits)\n",
    "timestamp_s = 1554092820\n",
    "datetime_s = datetime.fromtimestamp(timestamp_s)\n",
    "print(f\"If seconds: {datetime_s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 2565045\n",
      "Date range: from 1554074880000 to 1730545980000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Get all CSV files in the current directory\n",
    "csv_files = glob.glob('data/*.csv')\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Read each CSV file and append to the list\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Combine all DataFrames\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Sort by time column\n",
    "combined_df = combined_df.sort_values('time')\n",
    "\n",
    "# Remove duplicates if any\n",
    "combined_df = combined_df.drop_duplicates()\n",
    "\n",
    "# Save to new CSV file\n",
    "combined_df.to_csv('btc_historical_minutes.csv', index=False)\n",
    "\n",
    "# Print some information about the combined dataset\n",
    "print(f\"Total number of records: {len(combined_df)}\")\n",
    "print(f\"Date range: from {combined_df['time'].min()} to {combined_df['time'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 2565045\n",
      "Time range: from 1554074880000 to 1730545980000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('/Users/qn/dev/binary-prediction/btc_historical_minutes.csv')\n",
    "\n",
    "# Sort by time column (ascending order - lowest to highest)\n",
    "df = df.sort_values('time', ascending=True)\n",
    "\n",
    "# Save back to the same file\n",
    "df.to_csv('/Users/qn/dev/binary-prediction/btc_historical_minutes.csv', index=False)\n",
    "\n",
    "# Print some information to verify\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"Time range: from {df['time'].min()} to {df['time'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 2565045\n",
      "Number of 1s (close > open): 1286431\n",
      "Number of 0s (close <= open): 1278614\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('/Users/qn/dev/binary-prediction/btc_historical_minutes.csv')\n",
    "\n",
    "# Create prediction column (1 if close > open, 0 otherwise)\n",
    "df['prediction'] = (df['close'] > df['open']).astype(int)\n",
    "\n",
    "# Save to new file with \"_with_prediction\" appended\n",
    "new_filename = '/Users/qn/dev/binary-prediction/btc_historical_minutes_with_prediction.csv'\n",
    "df.to_csv(new_filename, index=False)\n",
    "\n",
    "# Print some information to verify\n",
    "print(f\"Total records: {len(df)}\")\n",
    "print(f\"Number of 1s (close > open): {df['prediction'].sum()}\")\n",
    "print(f\"Number of 0s (close <= open): {len(df) - df['prediction'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages (24.3.1)\n",
      "Requirement already satisfied: tensorflow in /opt/homebrew/lib/python3.11/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Users/qn/Library/Python/3.11/lib/python/site-packages (from tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (67.6.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/qn/Library/Python/3.11/lib/python/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: rich in /opt/homebrew/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/homebrew/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/homebrew/lib/python3.11/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/lib/python3.11/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/qn/Library/Python/3.11/lib/python/site-packages (from rich->keras>=3.5.0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# First, ensure pip is up to date\n",
    "!python -m pip install --upgrade pip\n",
    "\n",
    "# Install tensorflow\n",
    "!pip3 install tensorflow\n",
    "\n",
    "# If you're on Apple Silicon (M1/M2), you might need this instead:\n",
    "# !pip install tensorflow-macos tensorflow-metal\n",
    "\n",
    "# Verify installation\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.11.4 (main, Jun 20 2023, 17:23:00) [Clang 14.0.3 (clang-1403.0.22.14.1)]\n",
      "/opt/homebrew/Caskroom/miniconda/base/bin/pip\n",
      "pip 24.3.1 from /opt/homebrew/Caskroom/miniconda/base/lib/python3.10/site-packages/pip (python 3.10)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "!which pip\n",
    "!pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 23ms/step - accuracy: 0.5012 - loss: 0.6933 - val_accuracy: 0.5024 - val_loss: 0.6932\n",
      "Epoch 2/50\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 23ms/step - accuracy: 0.5015 - loss: 0.6932 - val_accuracy: 0.5043 - val_loss: 0.6931\n",
      "Epoch 3/50\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 23ms/step - accuracy: 0.5029 - loss: 0.6931 - val_accuracy: 0.5042 - val_loss: 0.6931\n",
      "Epoch 4/50\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 22ms/step - accuracy: 0.5034 - loss: 0.6931 - val_accuracy: 0.4958 - val_loss: 0.6932\n",
      "Epoch 5/50\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 22ms/step - accuracy: 0.5028 - loss: 0.6931 - val_accuracy: 0.4986 - val_loss: 0.6932\n",
      "Epoch 6/50\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 22ms/step - accuracy: 0.5014 - loss: 0.6931 - val_accuracy: 0.5042 - val_loss: 0.6931\n",
      "Epoch 7/50\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 22ms/step - accuracy: 0.5034 - loss: 0.6931 - val_accuracy: 0.5042 - val_loss: 0.6931\n",
      "Epoch 8/50\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m353s\u001b[0m 22ms/step - accuracy: 0.5027 - loss: 0.6931 - val_accuracy: 0.5042 - val_loss: 0.6931\n",
      "Epoch 9/50\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 22ms/step - accuracy: 0.5025 - loss: 0.6931 - val_accuracy: 0.5042 - val_loss: 0.6931\n",
      "Epoch 10/50\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m344s\u001b[0m 21ms/step - accuracy: 0.5030 - loss: 0.6931 - val_accuracy: 0.5042 - val_loss: 0.6931\n",
      "Epoch 11/50\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m345s\u001b[0m 22ms/step - accuracy: 0.5023 - loss: 0.6931 - val_accuracy: 0.4958 - val_loss: 0.6932\n",
      "Epoch 12/50\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 22ms/step - accuracy: 0.5033 - loss: 0.6931 - val_accuracy: 0.5042 - val_loss: 0.6931\n",
      "Epoch 12: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.5095 - loss: 0.6931\n",
      "\n",
      "Validation Accuracy: 50.43%\n",
      "\u001b[1m16032/16032\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2ms/step\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.60      0.54    254372\n",
      "         1.0       0.51      0.41      0.46    258633\n",
      "\n",
      "    accuracy                           0.50    513005\n",
      "   macro avg       0.51      0.51      0.50    513005\n",
      "weighted avg       0.51      0.50      0.50    513005\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\n",
      "Prediction for next minute: DOWN\n",
      "\n",
      "Model Architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m42,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m30,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">216,755</span> (846.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m216,755\u001b[0m (846.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">72,251</span> (282.23 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m72,251\u001b[0m (282.23 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">144,504</span> (564.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m144,504\u001b[0m (564.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load and preprocess the data\n",
    "data = pd.read_csv(\"btc_historical_minutes_with_prediction.csv\")\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "data.sort_values(by='time', inplace=True)\n",
    "\n",
    "# Prepare the target (21st minute's movement)\n",
    "data['target'] = data['prediction'].shift(-1)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Function to prepare sequences\n",
    "def prepare_sequences(data, window_size=20):  # Changed to 20\n",
    "    # Extract features and scale them\n",
    "    X = data[['open', 'close', 'high', 'low']].values\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    X_seq = []\n",
    "    y_seq = []\n",
    "    \n",
    "    # Create sequences: each X is 20 minutes of data, each y is the 21st minute\n",
    "    for i in range(window_size, len(X_scaled)):\n",
    "        X_seq.append(X_scaled[i-window_size:i])\n",
    "        y_seq.append(data['target'].iloc[i])\n",
    "    \n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# Prepare sequences with 20-minute window\n",
    "X, y = prepare_sequences(data, window_size=20)\n",
    "\n",
    "# Split data chronologically: 80% train, 20% validation\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Define model (adjusted for 20-minute input)\n",
    "model = Sequential([\n",
    "    LSTM(100, return_sequences=True, input_shape=(20, 4)),  # Changed input_shape\n",
    "    Dropout(0.2),\n",
    "    LSTM(50),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train model\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"\\nValidation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Make predictions on validation set\n",
    "predictions = model.predict(X_val)\n",
    "predictions_binary = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Print detailed metrics\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_val, predictions_binary))\n",
    "\n",
    "# Function to predict next minute\n",
    "def predict_next_minute(model, latest_data):\n",
    "    # Prepare the last 20 minutes of data\n",
    "    last_window = latest_data[-20:][['open', 'close', 'high', 'low']].values  # Changed to 20\n",
    "    scaler = StandardScaler()\n",
    "    last_window_scaled = scaler.fit_transform(last_window)\n",
    "    last_window_reshaped = last_window_scaled.reshape(1, 20, 4)  # Changed shape\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(last_window_reshaped)[0][0]\n",
    "    return \"UP\" if prediction > 0.5 else \"DOWN\"\n",
    "\n",
    "# Example of predicting the next minute\n",
    "latest_prediction = predict_next_minute(model, data)\n",
    "print(f\"\\nPrediction for next minute: {latest_prediction}\")\n",
    "\n",
    "# Print model summary\n",
    "print(\"\\nModel Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
